{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1e6a5196",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Geospatial Machine learning\"\n",
    "date: 2024-09-30\n",
    "date-format: short\n",
    "author: \"Glenn Moncrieff\"\n",
    "format: html\n",
    "execute: \n",
    "  enabled: false\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "682d514b-d10e-4cbe-b3b5-bc7d8d589dcf",
   "metadata": {},
   "source": [
    "### Mapping invasive species using supervised machine learning and AVIRIS-NG \n",
    "----\n",
    "\n",
    "### Overview \n",
    "----\n",
    "\n",
    "In this notebook, we will use existing data of verified land cover and alien species locations to extract spectra from AVIRIS NG surface reflectance data.\n",
    "\n",
    "- \n",
    "### Learning Objectives\n",
    "1. Understand how to inspect and prepare data for machine learning models\n",
    "2. Train and interpret a machine learning model\n",
    "3. Apply a trained model to AVIRIS imagery to create alien species maps\n",
    "\n",
    "### Requirements\n",
    "This tutorial requires the following Python modules installed `s3fs`, `rioxarray`, ...\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcc04b-ede1-44ce-8e6e-694f774e6e5e",
   "metadata": {},
   "source": [
    "### Load python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb49bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from shapely.geometry import box, mapping\n",
    "import rioxarray as riox\n",
    "import numpy as np\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import xvec\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365267bb",
   "metadata": {},
   "source": [
    "custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processes a multi-file datase\n",
    "#to extract the first valid reflectance measurement for each geometry. \n",
    "#iterates through the data, identifying the first non-null entry for each geometry across all files, \n",
    "#and then selects those specific reflectance values. \n",
    "\n",
    "def get_first_xr(ds_in):\n",
    "    #array with geomtery x files\n",
    "    arr = ds_in['index'].data\n",
    "    \n",
    "    #we want to find the first file where the geom is not null\n",
    "    # Initialize an array to store the indices of the first non-null entry for each column\n",
    "    file_ind = np.full(arr.shape[1], -1)  # Using -1 as a placeholder for no non-null values\n",
    "    \n",
    "    # Iterate over each column\n",
    "    for col_idx in range(arr.shape[1]):\n",
    "        # Get the column\n",
    "        col = arr[:, col_idx]\n",
    "        \n",
    "        # Find the index of the first non-null entry\n",
    "        non_null_indices = np.where(~np.isnan(col))[0]\n",
    "        \n",
    "        if non_null_indices.size > 0:\n",
    "            file_ind[col_idx] = non_null_indices[0]\n",
    "    \n",
    "    #create a list form 0 to len first_non_null_indices\n",
    "    geom_ind = list(range(len(file_ind)))\n",
    "    \n",
    "    file_ind = xr.DataArray(file_ind, dims=[\"index\"])\n",
    "    geom_ind = xr.DataArray(geom_ind, dims=[\"index\"])\n",
    "    \n",
    "    ds = ds_in['reflectance'][file_ind, geom_ind, :]\n",
    "    ds['index'] = ds['index'].astype(int)\n",
    "    raw_data_utm\n",
    "    #convert to dataset\n",
    "    ds = ds.to_dataset(name='reflectance')\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a39850-7206-401e-a519-896078b9ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "hvplot.extension('bokeh')\n",
    "#hvplot.extension('matplotlib')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe17082-4bea-4f3e-9faa-066c02392111",
   "metadata": {},
   "source": [
    "### 1. Open and explore land cover labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebfed43-b654-43b8-b61c-e0242f279c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lab = ['Bare ground/Rock','Mature Fynbos','Recently burnt Fynbos','Wetland','Forest','Pine','Eucalyptus','Wattle','Water']\n",
    "label = ['0','1','2','3','4','5','6','7','8']\n",
    "\n",
    "lab_df = pd.DataFrame({\n",
    "    'class': label,\n",
    "    'text_lab': text_lab\n",
    "})\n",
    "lab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74aa2ca-ff55-473b-ab21-0ad9f197c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = gpd.read_file('/home/gmoncrieff/ct_invasive.gpkg')\n",
    "raw_data_utm = (raw_data\n",
    "                .to_crs(\"EPSG:32734\")\n",
    "                .merge(lab_df, on='class', how='left')\n",
    "               )\n",
    "raw_data_utm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore data in interactive map. color by class. use google sattelite basemap\n",
    "(raw_data_utm[['text_lab','geometry']]\n",
    " .explore('text_lab',tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}', attr='Google'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638eb943-1aa9-4785-8719-eb467587ab64",
   "metadata": {},
   "source": [
    "### 2. Extract AVIRIS data at label locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff15df-1501-478e-970d-108bdd718476",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVNG_Coverage = gpd.read_file('ANG_Coverage.geojson')\n",
    "#filter dates to between midnight on 2023-11-09 and 23:59:59 on 2023-11-09\n",
    "AVNG_CP = AVNG_Coverage[(AVNG_Coverage['end_time'] >= '2023-11-09 00:00:00') & (AVNG_Coverage['end_time'] <= '2023-11-09 23:59:59')]\n",
    "#keep only AVNG_CP that intersects with raw_data\n",
    "AVNG_CP = AVNG_CP[AVNG_CP.intersects(raw_data.union_all())]\n",
    "\n",
    "#make a list of filenames\n",
    "files = AVNG_CP['RFL s3'].tolist()\n",
    "files.pop(70)\n",
    "\n",
    "#filter to start time between\n",
    "(AVNG_CP[['fid','geometry']]\n",
    " .explore('fid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd0616-6d4a-4043-a3f2-3cba1abe1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_dataset(files[30], engine='kerchunk', chunks='auto')\n",
    "test = test.where(test>0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b1743-3c9b-4590-bff3-3aafc643b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sel(wavelength=[660, 570, 480], method=\"nearest\").hvplot.rgb('x', 'y',\n",
    "                                                                  rasterize=True,data_aspect=1,robust=True,\n",
    "                                                                  bands='wavelength',frame_width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967ae98-bdc3-4934-8869-70bc7a7a0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sel({'wavelength': 660},method='nearest').hvplot('x', 'y',\n",
    "                                                      rasterize=True, data_aspect=1,robust=True,\n",
    "                                                      cmap='magma',frame_width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4232e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_points(file,points):\n",
    "    \n",
    "    ds = xr.open_dataset(file, engine='kerchunk', chunks='auto')\n",
    "    \n",
    "    # Get the bounding box coordinates\n",
    "    left, bottom, right, top = ds.rio.bounds()\n",
    "    \n",
    "    # Create a Shapely box geometry\n",
    "    bbox_shapely = box(left, bottom, right, top)\n",
    "    \n",
    "    # Clip the raw data to the bounding box\n",
    "    points = points.clip(bbox_shapely)\n",
    "    print(f'got {points.shape[0]} point from {file}')\n",
    "    \n",
    "    # Extract points\n",
    "    extracted = ds.xvec.extract_points(points['geometry'], x_coords=\"x\", y_coords=\"y\",index=True)\n",
    "    \n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba10bc-5ba3-4fa1-8cd1-f2261cf13bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = [extract_points(file,raw_data_utm) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75782566",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all  = xr.concat(ds_all, dim='file')\n",
    "ds_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bd2fa",
   "metadata": {},
   "source": [
    "extract the first valid reflectance measurement for each geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284703b-58d3-467f-9167-0f42ba74c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = get_first_xr(ds_all)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710178fd",
   "metadata": {},
   "source": [
    "merge with point data to add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e7c9c-4c36-44d0-a572-7133699657fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_xr =raw_data_utm[['class','group']].to_xarray()\n",
    "ds = ds.merge(class_xr.astype(int),join='left')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf47817",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    " dsp = ds.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0513ac4-0071-4f99-9c29-d59ee2286ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af28ea-8400-4496-8496-fbdc3e1ba039",
   "metadata": {},
   "source": [
    "### 3. Inspect AVIRIS spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_plot = dsp.where(dsp['class']==0, drop=True)\n",
    "dsp_plot['reflectance'].hvplot.line(x='wavelength',by='index',\n",
    "                                    color='green',ylim=(0,0.5),alpha=0.5,legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c8fcd-a083-45b1-818b-48afa04bf907",
   "metadata": {},
   "source": [
    "> edit data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c07268-1b4d-462a-a2a0-853afbdb86c1",
   "metadata": {},
   "source": [
    "### 4. Prep data for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a86ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths_to_drop = ds.wavelength.where(\n",
    "    (ds.wavelength < 420) |\n",
    "    (ds.wavelength >= 1340) & (ds.wavelength <= 1450) |\n",
    "    (ds.wavelength >= 1800) & (ds.wavelength <= 1980) |\n",
    "    (ds.wavelength > 2400), drop=True\n",
    ")\n",
    "\n",
    "# Use drop_sel() to remove those specific wavelength ranges\n",
    "dsp = dsp.drop_sel(wavelength=wavelengths_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the L2 norm along the 'wavelength' dimension in a Dask-aware way\n",
    "l2_norm = np.sqrt((dsp['reflectance'] ** 2).sum(dim='wavelength'))\n",
    "\n",
    "# Normalize the reflectance by dividing by the L2 norm\n",
    "dsp['reflectance'] = dsp['reflectance'] / l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_norm_plot = dsp.where(dsp['class']==4, drop=True)\n",
    "dsp_norm_plot['reflectance'].hvplot.line(x='wavelength',by='index',\n",
    "                                         color='green',ylim=(0,0.2),alpha=0.5,legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fa6a0-f5f8-46c4-bee8-d11847c88876",
   "metadata": {},
   "source": [
    "### 5. Train and evaluate ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53485c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036f9bb-aaa7-429c-a4f8-663296cd1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = dsp.where(dsp['group']==1,drop=True)\n",
    "dtest = dsp.where(dsp['group']==2,drop=True)\n",
    "\n",
    "y_train = dtrain['class'].values.astype(int)\n",
    "y_test = dtest['class'].values.astype(int)\n",
    "X_train = dtrain['reflectance'].values\n",
    "X_test = dtest['reflectance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f577b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = dsp.where(dsp['group']==1,drop=True)\n",
    "dtest = dsp.where(dsp['group']==2,drop=True)\n",
    "# Label encode the class variable\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(dtrain['class'].values)\n",
    "y_test = le.transform(dtest['class'].values)\n",
    "X_train = dtrain['reflectance'].values\n",
    "X_test = dtest['reflectance'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71469fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 250, 500],\n",
    "    'max_depth': [3, 5, 9],\n",
    "    'learning_rate': [0.1, 0.1, 0.001],\n",
    "    'subsample': [0.5, 1],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.5, 1],\n",
    "    'n_estimators' : [50,100]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBClassifier(tree_method='hist')\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20eee2-96be-4bc9-9abc-3268d2591055",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Step 2: Calculate F1 score for the entire dataset\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for class imbalance\n",
    "print(f\"F1 Score (weighted): {f1}\")\n",
    "\n",
    "# Step 3: Calculate precision and recall for class 3\n",
    "precision_class_3 = precision_score(y_test, y_pred, labels=[3], average='macro', zero_division=0)\n",
    "recall_class_3 = recall_score(y_test, y_pred, labels=[3], average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Precision for Class 3: {precision_class_3}\")\n",
    "print(f\"Recall for Class 3: {recall_class_3}\")\n",
    "\n",
    "# Step 4: Plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fcd43b-5ddc-405c-81dc-826db8178a44",
   "metadata": {},
   "source": [
    "> conformal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694182c4-6384-4907-9c99-291b07dff60f",
   "metadata": {},
   "source": [
    "### 6. Interpret and understand ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7aa05b-2712-465d-ae55-49eb156d3687",
   "metadata": {},
   "source": [
    "SHAP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c682966-758e-4afd-8776-c1b25014da8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "#shap.initjs()\n",
    "\n",
    "# Initialize the SHAP Tree Explainer for XGBoost\n",
    "explainer = shap.TreeExplainer(best_model,feature_names=list(map(str, dsp.wavelength.values.astype(int))))\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147fe38e-7022-43b3-a877-84f28e6fcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_in = 5\n",
    "shap.plots.waterfall(shap_values[sel_in,:,y_test[sel_in]])\n",
    "\n",
    "\n",
    "#lables for wavelength in plot\n",
    "#feats =  dsp.wavelength.values.astype(int)\n",
    "#feats = map(str,feats)\n",
    "#shap.force_plot(explainer.expected_value[y_test[sel_in]], shap_values.values[sel_ind,:,y_test[sel_in]], pd.DataFrame(X_test).iloc[sel_ind, :],link='logit',feature_names=list(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972cd26-eef5-4d11-927f-f0a70bfd5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values[:,:,y_test[sel_in]].abs, color=\"shap_red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e04587-9d89-4398-9b52-27386f132635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spectra and importance\n",
    "importance = np.abs(shap_values[sel_in,:,y_test[sel_in]].values)\n",
    "# Create the base plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Get the wavelength and importance data\n",
    "wavelength = dsp['wavelength'].values\n",
    "importance = importance  # Make sure this aligns with your wavelength data\n",
    "\n",
    "# Create a colormap\n",
    "cmap = plt.get_cmap('hot').reversed()  # You can choose a different colormap if you prefer\n",
    "\n",
    "# Normalize importance values to [0, 1] for colormap\n",
    "norm = plt.Normalize(importance.min(), importance.max())\n",
    "\n",
    "# Add shading\n",
    "for i in range(len(wavelength) - 1):\n",
    "    ax.fill_between([wavelength[i], wavelength[i+1]], 0, 1, \n",
    "                    color=cmap(norm(importance[i])), alpha=0.3)\n",
    "\n",
    "# Add a colorbar to show the importance scale\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, label='Importance')\n",
    "\n",
    "# Add white blocks to obscure specified regions\n",
    "ax.fill_between([0,420], 0, 1, color='white')\n",
    "ax.fill_between([1340,1458], 0, 1, color='white')\n",
    "ax.fill_between([1800,1980], 0, 1, color='white')\n",
    "ax.fill_between([2400,2500], 0, 1, color='white')\n",
    "ax.set_xlim(420,2400)\n",
    "\n",
    "plot_xr = xr.DataArray(X_test[sel_in], coords=[wavelength], dims=[\"wavelength\"])\n",
    "plot_xr.plot.line(x='wavelength', color='green', ylim=(0, 0.2), ax=ax,zorder=0)\n",
    "\n",
    "plt.title('Reflectance with Importance Shading')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Reflectance (normalized)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea5c8f-fd79-4572-b22a-b7e7b997d5bf",
   "metadata": {},
   "source": [
    "### 7. Prep AVIRIS scenes or prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e080ea8-bf98-4534-a941-e5bb77db84a6",
   "metadata": {},
   "source": [
    "Let me explain the key components of this solution:\n",
    "\n",
    "predict_on_chunk function:\n",
    "\n",
    "This function is designed to work on individual chunks of your data.\n",
    "It ensures the input is a numpy array and reshapes it if necessary to match your model's input requirements.\n",
    "It applies the model's predict function to the chunk.\n",
    "\n",
    "\n",
    "predict_xarray function:\n",
    "\n",
    "This function uses xarray's apply_ufunc to apply the predict_on_chunk function across your entire dataset.\n",
    "It respects the chunking of your xarray DataArray and processes data chunk by chunk.\n",
    "The input_core_dims=[['wavelength']] specifies that the 'wavelength' dimension should be passed to the function.\n",
    "output_core_dims=[[]] assumes that the prediction output is a single value per sample. Adjust this if your model outputs multiple values per sample.\n",
    "vectorize=True allows the function to work on arrays.\n",
    "dask='allowed' enables parallel processing with dask.\n",
    "\n",
    "\n",
    "Usage:\n",
    "\n",
    "You can apply this function to your xarray DataArray.\n",
    "The compute() call at the end triggers the actual computation and returns the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c154fb9-8ada-480b-86e2-1d2edfe4795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAPAD = (gpd.read_file('SAPAD_2024.gpkg')\n",
    "         .query(\"SITE_TYPE!='Marine Protected Area'\")\n",
    "        )\n",
    "# Get the bounding box of the first GeoDataFrame\n",
    "bbox = raw_data.total_bounds  # (minx, miny, maxx, maxy)\n",
    "gdf_bbox = gpd.GeoDataFrame({'geometry': [box(*bbox)]}, crs=raw_data.crs)  # Specify the CRS\n",
    "gdf_bbox['geometry'] = gdf_bbox.buffer(0.02)\n",
    "\n",
    "# Filter the second GeoDataFrame to keep only the rows that intersect with the buffered bbox\n",
    "SAPAD_CT = SAPAD.overlay(gdf_bbox,how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8a116-527e-4161-9917-c2a73ad28cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAPAD_CT.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ee786-9a02-4a5c-bd74-fa75d1a5f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only AVNG_CP that intersects with raw_data\n",
    "AVNG_sapad = AVNG_CP[AVNG_CP.intersects(SAPAD_CT.union_all())]\n",
    "files_sapad = AVNG_sapad['RFL s3'].tolist()\n",
    "geometries_sapad = SAPAD_CT.to_crs(\"EPSG:32734\").geometry.apply(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5472a14-d86f-4887-933f-8137bc7296f8",
   "metadata": {},
   "source": [
    "### 8. Predict over multiple AVIRIS scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a63d9-46f8-41c1-bad4-60104a83c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_on_chunk(chunk, model):\n",
    "    probabilities = model.predict_proba(chunk)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d66939-642a-4033-9197-42c83d4c8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_s=files_sapad[62:70]\n",
    "files_s=files_sapad\n",
    "# Get the number of classes from a small prediction\n",
    "n_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335ad22-511e-4ed2-8474-2bddc1cf3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_s.pop(85)\n",
    "files_s.pop(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41debacf-b44f-4960-8266-74bc8fdf0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xr(file,geometries):\n",
    "    print(f'file: {file}')\n",
    "    ds = xr.open_dataset(file, engine='kerchunk', chunks='auto')\n",
    "    #condition to use for masking no data later\n",
    "    \n",
    "    condition = (ds['reflectance'] > 0).any(dim='wavelength')\n",
    "    ds = ds.stack(sample=('x','y'))\n",
    "    \n",
    "    wavelengths_to_drop = ds.wavelength.where(\n",
    "        (ds.wavelength < 420) |\n",
    "        (ds.wavelength >= 1340) & (ds.wavelength <= 1450) |\n",
    "        (ds.wavelength >= 1800) & (ds.wavelength <= 1980) |\n",
    "        (ds.wavelength > 2400), drop=True\n",
    "    )\n",
    "    \n",
    "    # Use drop_sel() to remove those specific wavelength ranges\n",
    "    ds = ds.drop_sel(wavelength=wavelengths_to_drop)\n",
    "    \n",
    "    # Calculate the L2 norm along the 'wavelength' dimension in a Dask-aware way\n",
    "    l2_norm = np.sqrt((ds['reflectance'] ** 2).sum(dim='wavelength'))\n",
    "    \n",
    "    # Normalize the reflectance by dividing by the L2 norm\n",
    "    ds['reflectance'] = ds['reflectance'] / l2_norm\n",
    "    \n",
    "    \n",
    "    # Use apply_ufunc to apply the prediction function over chunks\n",
    "    result = xr.apply_ufunc(\n",
    "        predict_proba_on_chunk,\n",
    "        ds['reflectance'],\n",
    "        input_core_dims=[['wavelength']],#input dim with features\n",
    "        output_core_dims=[['class']],  # output dims for probabilities\n",
    "        exclude_dims=set(('wavelength',)),  #dims to drop in result\n",
    "        output_sizes={'class': n_classes},\n",
    "        output_dtypes=[np.float32],\n",
    "        dask=\"parallelized\",\n",
    "        kwargs={'model': best_model}\n",
    "    )\n",
    "    result = result.unstack('sample')\n",
    "    result = result.rio.set_spatial_dims(x_dim='x',y_dim='y')\n",
    "    result = result.rio.write_crs(\"EPSG:32734\")\n",
    "    result = result.rio.clip(geometries).where(condition)\n",
    "    result = result.transpose('class', 'y', 'x')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bff7d-cd87-43a8-a8d5-09cd99862c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = predict_xr(files_s[53],geometries_sapad)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71497790-f98a-44e3-9243-b17c636cc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rio.reproject(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad84c2-816e-4f4e-987b-dbfe903c59bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.isel({'class':0}).hvplot(tiles=hv.element.tiles.EsriImagery(), \n",
    "                              project=True,rasterize=True,robust=True,\n",
    "                              cmap='magma',frame_width=400,data_aspect=1,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8f636-ddf3-4bdd-aa4c-b18fe7a42a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pred = [predict_xr(fi,geometries_sapad) for fi in files_s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d50e9c-d6a0-47d2-86ca-f416a1e6b0f4",
   "metadata": {},
   "source": [
    "## 9. Merge and mosaic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c79675-2581-4a57-992e-d9eaa4811053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rioxarray.merge import merge_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f03f2b-01b0-4e3f-b3c6-711eeb056a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_arrays(grid_pred)\n",
    "merged = merged.rio.reproject(\"EPSG:4326\")\n",
    "merged.rio.to_raster('/home/gmoncrieff/ct_invasive.tiff',driver=\"COG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27816e6-52cc-4190-8953-dae4dc7c7d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = xr.open_dataset('/home/gmoncrieff/ct_invasive.tiff', engine='rasterio', chunks='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfae5bf-5172-40b0-af4c-1b7b9c2341ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04d01b-fab5-494a-a3ca-b5132e62c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.isel({'band':6}).hvplot(x='x',y='y',tiles=hv.element.tiles.EsriImagery(),\n",
    "                               geo=True,\n",
    "                                project=True,rasterize=True,robust=True,\n",
    "                                cmap='magma',clim=(0,1), frame_width=400,data_aspect=1,alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca17852",
   "metadata": {},
   "source": [
    "> return to step 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmoncrieff-gmoncrieff-ml",
   "language": "python",
   "name": "conda-env-gmoncrieff-gmoncrieff-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
